{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "####### Imports #######\n",
    "#######################\n",
    "\n",
    "# Flask App Imports\n",
    "from flask import Flask, jsonify, request, json\n",
    "from flask_restful import Api, reqparse\n",
    "from flask_cors import CORS\n",
    "\n",
    "# The usuals\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# System Imports\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Selenium Imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# Other imports\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import spacy\n",
    "\n",
    "# Functions (Local Imports)\n",
    "from functions import (\n",
    "    clear_auto, deep_indeed_query, clean_jobs,\n",
    "    indeed_crawl, clean_description, tokenize,\n",
    "    fit_for_nn, transform_query_for_nn, parse\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin-Up Web Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Disable auto-complete\n",
    "profile = webdriver.FirefoxProfile()\n",
    "profile.set_preference(\"browser.formfill.enable\", \"false\")\n",
    "    \n",
    "# Create new Instance of Chrome in incognito mode\n",
    "browser = webdriver.Firefox(executable_path='../../Selenium/geckodriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titles and locations\n",
    "titles = [\"Chemical Engineer\", \"Process Engineer\", \"Environmental Engineer\"]\n",
    "locations = [\"Raleigh-Durham, NC\", \"Charlotte, NC\", \"Roanoke, VA\", \"Charlottesville, VA\",\n",
    "             \"Greensboro, NC\", \"Winston-Salem, NC\", \"Annapolis, MD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: Chemical Engineer - Raleigh-Durham, NC\n",
      "Scraping: Process Engineer - Raleigh-Durham, NC\n",
      "Scraping: Environmental Engineer - Raleigh-Durham, NC\n",
      "Scraping: Chemical Engineer - Charlotte, NC\n",
      "Scraping: Process Engineer - Charlotte, NC\n",
      "Scraping: Environmental Engineer - Charlotte, NC\n",
      "Scraping: Chemical Engineer - Roanoke, VA\n",
      "Scraping: Process Engineer - Roanoke, VA\n",
      "Scraping: Environmental Engineer - Roanoke, VA\n",
      "Scraping: Chemical Engineer - Charlottesville, VA\n",
      "Scraping: Process Engineer - Charlottesville, VA\n",
      "Scraping: Environmental Engineer - Charlottesville, VA\n",
      "Scraping: Chemical Engineer - Greensboro, NC\n",
      "Scraping: Process Engineer - Greensboro, NC\n",
      "Scraping: Environmental Engineer - Greensboro, NC\n",
      "Scraping: Chemical Engineer - Winston-Salem, NC\n",
      "Scraping: Process Engineer - Winston-Salem, NC\n",
      "Scraping: Environmental Engineer - Winston-Salem, NC\n",
      "Scraping: Chemical Engineer - Annapolis, MD\n",
      "Scraping: Process Engineer - Annapolis, MD\n",
      "Scraping: Environmental Engineer - Annapolis, MD\n",
      "Scraping: Chemical Engineer - Ann Arbor, MI\n",
      "Scraping: Process Engineer - Ann Arbor, MI\n",
      "Scraping: Environmental Engineer - Ann Arbor, MI\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dirty_jobs\n",
    "dirty_jobs = []\n",
    "\n",
    "# Crawl over indeed.com\n",
    "jobs = indeed_crawl(titles, locations, dirty_jobs, browser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button class=\"icl-Button icl-Button--primary icl-Button--md icl-WhatWhere-button\" size=\"md\" type=\"submit\">Find Jobs</button>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = parse(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [str(text)[1:-1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send to df\n",
    "df = pd.DataFrame(texts, columns = ['description'])\n",
    "df['jobs'] = jobs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Model\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and tokenize the descriptions\n",
    "df['tokens'] = tokenize(df['description'].apply(clean_description).tolist(), nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send clean text to list\n",
    "text = df['description'].apply(clean_description).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dtm = fit_for_nn(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vocab and get word counts per doc\n",
    "sparse = tfidf.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send to df\n",
    "tfidf_dtm = pd.DataFrame(sparse.todense(), columns = tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "nn = NearestNeighbors(n_neighbors=20, algorithm='ball_tree')\n",
    "nn.fit(tfidf_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"I use python to collect and scrape data from the web. I can set up integrated data pipelines\n",
    "        pipeline to collect data from different sources. I train machine learning models using sklearn, \n",
    "        and tensorflow with keras. BeautifulSoup and Selenium. BeautifulSoup and Selenium.\n",
    "        BeautifulSoup and Selenium. BeautifulSoup and Selenium. I can give results to developers using Flask apps\n",
    "        and Flask APIs API. I can access APIs API and RSS feeds. I can also use SQL, particularly ElephantSQL\n",
    "        and Postgres. I like venture capital, finance and business consulting. I love to work with\n",
    "        natural language processing. Looking for a junior or entry level entry-level or mid level mid-level\n",
    "        venture capital, finance and business consulting venture capital, finance and business consulting\n",
    "        venture capital, finance and business consulting venture capital, finance and business consulting\"\"\"\n",
    "\n",
    "# query = \"\"\"I use knowledge of process and chemical engineering to help businesses optimize production,\n",
    "#         often making use of Statistical Process Control.  Background in math, science, organic chemistry.\n",
    "#         Interested in the environmental waste section, as chemistry forms the backbone of much of that work.\"\"\"\n",
    "\n",
    "# query = \"\"\"behavioral sciences intern working with children or adults with disablities behavioral therapy\n",
    "#         graphic design personalized personal disabled\"\"\"\n",
    "\n",
    "query_dtm = process_query_for_nn(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for closest neighbors\n",
    "results = nn.kneighbors(query_dtm)[1][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Send to list\n",
    "job_urls = df['jobs'][results].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create links\n",
    "def make_clickable(val):\n",
    "    return '<a href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "jobs_df = pd.DataFrame(job_urls)\n",
    "\n",
    "jobs_df.style.format(make_clickable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
